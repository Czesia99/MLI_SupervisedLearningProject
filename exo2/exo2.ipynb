{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipdb\n",
    "import pandas as pd\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "general info on the dataframe\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            200 non-null    int64  \n",
      " 1   age                   200 non-null    float64\n",
      " 2   height                200 non-null    float64\n",
      " 3   job                   200 non-null    object \n",
      " 4   city                  200 non-null    object \n",
      " 5   favorite music style  200 non-null    object \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "---\n",
      "columns of the dataset\n",
      "Index(['Unnamed: 0', 'age', 'height', 'job', 'city', 'favorite music style'], dtype='object')\n",
      "---\n",
      "first lines\n",
      "   Unnamed: 0        age      height         job       city   \n",
      "0           0  30.237071  179.874298    designer      paris  \\\n",
      "1           1  27.915796  172.659587     fireman  marseille   \n",
      "2           2  32.205338  181.337491     teacher      paris   \n",
      "3           3  26.595215  172.337885    designer   toulouse   \n",
      "4           4  27.394780  182.708030     teacher      paris   \n",
      "5           5  29.710022  177.037196      doctor   toulouse   \n",
      "6           6  41.789490  188.476525     fireman  marseille   \n",
      "7           7  36.665622  175.102745     painter   toulouse   \n",
      "8           8  33.838742  176.441942     painter      paris   \n",
      "9           9  30.037158  191.462290  developper      paris   \n",
      "\n",
      "  favorite music style  \n",
      "0                 trap  \n",
      "1               hiphop  \n",
      "2                metal  \n",
      "3                metal  \n",
      "4                metal  \n",
      "5                 rock  \n",
      "6                  rap  \n",
      "7                 rock  \n",
      "8            classical  \n",
      "9                 trap  \n",
      "---\n",
      "Standard deviation\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: 'designer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/nanops.py:1004\u001b[0m, in \u001b[0;36mnanvar\u001b[0;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[39m# xref GH10242\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[39m# Compute variance via two-pass algorithm, which is stable against\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[39m# cancellation errors and relatively accurate for small numbers of\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[39m# observations.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[39m# See https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m avg \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64)) \u001b[39m/\u001b[39m count\n\u001b[1;32m   1005\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'designer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m     dot\u001b[39m.\u001b[39mrender(graph_name)\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 127\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m---> 30\u001b[0m     print_data_info()\n\u001b[1;32m     31\u001b[0m     dissimilarity_matrix()\n\u001b[1;32m     32\u001b[0m     render_graph()\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m, in \u001b[0;36mprint_data_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# print the correlation matrix of the dataset\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m#print(\"---\\nCorrelation matrix\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m#print(dataframe.corr())\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[39m# print the standard deviation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m---\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStandard deviation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mprint\u001b[39m(dataframe\u001b[39m.\u001b[39;49mstd())\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/generic.py:11424\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.std\u001b[0;34m(self, axis, skipna, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11405\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11406\u001b[0m     _num_ddof_doc,\n\u001b[1;32m  11407\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn sample standard deviation over requested axis.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11422\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11423\u001b[0m ):\n\u001b[0;32m> 11424\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mstd(\u001b[39mself\u001b[39;49m, axis, skipna, ddof, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/generic.py:11137\u001b[0m, in \u001b[0;36mNDFrame.std\u001b[0;34m(self, axis, skipna, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstd\u001b[39m(\n\u001b[1;32m  11130\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11131\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11135\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11136\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function_ddof(\n\u001b[1;32m  11138\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mstd\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanstd, axis, skipna, ddof, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11139\u001b[0m     )\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/generic.py:11101\u001b[0m, in \u001b[0;36mNDFrame._stat_function_ddof\u001b[0;34m(self, name, func, axis, skipna, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11098\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m  11099\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stat_axis_number\n\u001b[0;32m> 11101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11102\u001b[0m     func, name, axis\u001b[39m=\u001b[39;49maxis, numeric_only\u001b[39m=\u001b[39;49mnumeric_only, skipna\u001b[39m=\u001b[39;49mskipna, ddof\u001b[39m=\u001b[39;49mddof\n\u001b[1;32m  11103\u001b[0m )\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/frame.py:10524\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  10520\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mT\n\u001b[1;32m  10522\u001b[0m \u001b[39m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  10523\u001b[0m \u001b[39m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 10524\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreduce(blk_func)\n\u001b[1;32m  10525\u001b[0m out \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_constructor(res)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[1;32m  10526\u001b[0m \u001b[39mif\u001b[39;00m out_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1532\u001b[0m res_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[1;32m   1533\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m-> 1534\u001b[0m     nbs \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mreduce(func)\n\u001b[1;32m   1535\u001b[0m     res_blocks\u001b[39m.\u001b[39mextend(nbs)\n\u001b[1;32m   1537\u001b[0m index \u001b[39m=\u001b[39m Index([\u001b[39mNone\u001b[39;00m])  \u001b[39m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce\u001b[39m(\u001b[39mself\u001b[39m, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[1;32m    335\u001b[0m     \u001b[39m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[39m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m--> 339\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues)\n\u001b[1;32m    341\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    342\u001b[0m         \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    343\u001b[0m         res_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[result]])\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/frame.py:10487\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  10485\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39m_reduce(name, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m  10486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m> 10487\u001b[0m     \u001b[39mreturn\u001b[39;00m op(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/nanops.py:940\u001b[0m, in \u001b[0;36mnanstd\u001b[0;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[1;32m    937\u001b[0m orig_dtype \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    938\u001b[0m values, mask, _, _, _ \u001b[39m=\u001b[39m _get_values(values, skipna, mask\u001b[39m=\u001b[39mmask)\n\u001b[0;32m--> 940\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(nanvar(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, ddof\u001b[39m=\u001b[39;49mddof, mask\u001b[39m=\u001b[39;49mmask))\n\u001b[1;32m    941\u001b[0m \u001b[39mreturn\u001b[39;00m _wrap_results(result, orig_dtype)\n",
      "File \u001b[0;32m~/epitech/MLI_SupervisedLearningProject/.venv/lib/python3.10/site-packages/pandas/core/nanops.py:103\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 103\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: could not convert string to float: 'designer'"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"dataset.csv\")\n",
    "nb_people = len(dataframe.index)\n",
    "\n",
    "def print_data_info():\n",
    "        # general info on the dataframe\n",
    "    print(\"---\\ngeneral info on the dataframe\")\n",
    "    print(dataframe.info())\n",
    "\n",
    "    # print the columns of the dataframe\n",
    "    print(\"---\\ncolumns of the dataset\")\n",
    "    print(dataframe.columns)\n",
    "\n",
    "    # print the first 10 lines of the dataframe\n",
    "    print(\"---\\nfirst lines\")\n",
    "    print(dataframe.head(10))\n",
    "\n",
    "    # print the correlation matrix of the dataset\n",
    "    #print(\"---\\nCorrelation matrix\")\n",
    "    #print(dataframe.corr())\n",
    "\n",
    "    # print the standard deviation\n",
    "    print(\"---\\nStandard deviation\")\n",
    "    print(dataframe.std())\n",
    "\n",
    "def print_specific_value(id, dataframe):\n",
    "    print(\"---\\nall info on player \" + str(id))\n",
    "    print(dataframe.loc[id])\n",
    "\n",
    "def main():\n",
    "    print_data_info()\n",
    "    dissimilarity_matrix()\n",
    "    render_graph()\n",
    "\n",
    "def compute_dissimilarity(id1, id2):\n",
    "    entity_1_age = dataframe.loc[id1][1]\n",
    "    entity_2_age = dataframe.loc[id2][1]\n",
    "\n",
    "    entity_1_height = dataframe.loc[id1][2]\n",
    "    entity_2_height = dataframe.loc[id2][2]\n",
    "\n",
    "    entity_1_job = dataframe.loc[id1][3]\n",
    "    entity_2_job = dataframe.loc[id2][3]\n",
    "\n",
    "    entity_1_city = dataframe.loc[id1][4]\n",
    "    entity_2_city = dataframe.loc[id2][4]\n",
    "\n",
    "    entity_1_music_style = dataframe.loc[id1][5]\n",
    "    entity_2_music_style = dataframe.loc[id2][5]\n",
    "\n",
    "    if entity_1_job == entity_2_job:\n",
    "        dissimilarity_job = 0\n",
    "    else:\n",
    "        dissimilarity_job = 15\n",
    "    \n",
    "    if entity_1_city == entity_2_city:\n",
    "        dissimilarity_city = 0\n",
    "    else:\n",
    "        dissimilarity_city = 15\n",
    "\n",
    "    if entity_1_music_style == entity_2_music_style:\n",
    "        dissimilarity_music_style = 0\n",
    "    elif entity_1_music_style == \"technical death metal\" and entity_2_music_style == \"metal\":\n",
    "        dissimilarity_music_style = 5 \n",
    "    else:\n",
    "        dissimilarity_music_style= 15\n",
    "    \n",
    "    dissimilarity = math.sqrt(\n",
    "        (entity_1_age - entity_2_age) ** 2\n",
    "        + 3 * (entity_1_height - entity_2_height) ** 2\n",
    "        + dissimilarity_job\n",
    "        + dissimilarity_city\n",
    "        + dissimilarity_music_style\n",
    "    )\n",
    "\n",
    "    print(\"==========\")\n",
    "    entity_1_id = dataframe.loc[entity_1_id][0]\n",
    "    entity_2_id = dataframe.loc[entity_2_id][0]\n",
    "    print(\n",
    "        f\"entity1 {entity_1_id}, entity_2_id {entity_2_id}, dissimilarity: {dissimilarity}\"\n",
    "    )\n",
    "    return dissimilarity\n",
    "\n",
    "def dissimilarity_matrix():\n",
    "    dm = np.zeros((nb_people, nb_people))\n",
    "    print(\"compute dissimilarities...\")\n",
    "    for entity_1_id in range(nb_people):\n",
    "        for entity_2_id in range(nb_people):\n",
    "            dissimilarity = compute_dissimilarity(entity_1_id, entity_2_id)\n",
    "            dissimilarity_matrix[entity_1_id, entity_2_id] = dissimilarity\n",
    "    print(\"====== dissimilarity matrix ======\")\n",
    "    print(dissimilarity_matrix)\n",
    "\n",
    "    return dissimilarity_matrix\n",
    "\n",
    "def render_graph():\n",
    "    threshold = 15\n",
    "\n",
    "    dot = Graph(comment=\"Graph created from complex data\", strict=True)\n",
    "    for entity in range(nb_people):\n",
    "        entity_id = dataframe.loc[entity_id][0]\n",
    "        dot.node(entity_id)\n",
    "\n",
    "    for entity_1 in range(nb_people):\n",
    "        # we use an undirected graph so we do not need\n",
    "        # to take the potential reciprocal edge\n",
    "        # into account\n",
    "        for entity_2 in range(nb_people):\n",
    "            # no self loops\n",
    "            if not entity_1 == entity_2:\n",
    "                entity_1_id = dataframe.loc[entity_1_id][0]\n",
    "                entity_2_id = dataframe.loc[entity_2_id][0]\n",
    "                # use the threshold condition\n",
    "                # EDIT THIS LINE\n",
    "                if dissimilarity_matrix[entity_1, entity_2] > threshold:\n",
    "                    dot.edge(\n",
    "                        entity_1_id,\n",
    "                        entity_2_id,\n",
    "                        color=\"darkolivegreen4\",\n",
    "                        penwidth=\"1.1\",\n",
    "                    )\n",
    "    # visualize the graph\n",
    "    dot.attr(label=f\"threshold {threshold}\", fontsize=\"20\")\n",
    "    graph_name = f\"complex_data_threshold_{threshold}\"\n",
    "    dot.render(graph_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
